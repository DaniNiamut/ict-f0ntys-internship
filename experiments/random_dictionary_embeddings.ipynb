{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a0e4ce24",
   "metadata": {},
   "source": [
    "This code is meant to test the performance of random dictionary embeddings for classification purposes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8394e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4e9e5b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.datasets as datasets\n",
    "from torch.utils.data import ConcatDataset\n",
    "from sklearn.model_selection import KFold\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from botorch.acquisition.analytic import (LogExpectedImprovement, UpperConfidenceBound,\n",
    "                                        ProbabilityOfImprovement)\n",
    "from botorch.acquisition import qLogExpectedImprovement, qUpperConfidenceBound, qProbabilityOfImprovement\n",
    "from botorch.optim import optimize_acqf\n",
    "from botorch.models import SingleTaskGP\n",
    "from bodi import HammingEmbeddingDictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b69dcc5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = 15\n",
    "cat_classes = [2, 3, 4, 5, 3, 6, 2, 4, 3, 5]\n",
    "num_cont = 10\n",
    "num_cat_features = len(cat_classes)\n",
    "\n",
    "cat_features = []\n",
    "\n",
    "for num_classes in cat_classes:\n",
    "    probs = torch.rand(num_samples, num_classes)\n",
    "    probs = torch.softmax(probs, dim=1)\n",
    "    samples = torch.multinomial(probs, num_samples=1).squeeze(1)\n",
    "    cat_features.append(samples)\n",
    "\n",
    "cat_var = torch.stack(cat_features, dim=1)\n",
    "cont_features = torch.rand(num_samples, num_cont)\n",
    "train_X = torch.cat((cat_var.float(), cont_features), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "25a55f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\danin\\AppData\\Local\\Temp\\ipykernel_22464\\3225654135.py:8: InputDataWarning: The model inputs are of type torch.float32. It is strongly recommended to use double precision in BoTorch, as this improves both precision and stability and can help avoid numerical errors. See https://github.com/pytorch/botorch/discussions/1444\n",
      "  gp = SingleTaskGP(train_X, train_Y, input_transform=inp)\n",
      "c:\\Users\\danin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\botorch\\optim\\optimize.py:652: RuntimeWarning: Optimization failed in `gen_candidates_scipy` with the following warning(s):\n",
      "[OptimizationWarning('Optimization failed within `scipy.optimize.minimize` with status 2 and message ABNORMAL: .')]\n",
      "Trying again with a new set of initial conditions.\n",
      "  return _optimize_acqf_batch(opt_inputs=opt_inputs)\n"
     ]
    }
   ],
   "source": [
    "inp = HammingEmbeddingDictionary(cat_dims=[0,1,2,3,4,5,6,7,8,9], \n",
    "                                      reduced_cat_dim=2, \n",
    "                                      classes_per_cat=cat_classes\n",
    "                                      #cont bounds\n",
    "                                      )\n",
    "\n",
    "train_Y = torch.sin(train_X).sum(dim=1, keepdim=True)\n",
    "gp = SingleTaskGP(train_X, train_Y, input_transform=inp)\n",
    "\n",
    "bounds = (torch.min(train_X, 0)[0], torch.max(train_X, 0)[0])\n",
    "bounds = torch.stack(bounds)\n",
    "\n",
    "acq_func = qLogExpectedImprovement(gp, train_Y.max())\n",
    "candidate, acq_value = optimize_acqf(acq_func, bounds=bounds, q=2, num_restarts=5, raw_samples=20,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "696e0fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpytorch.kernels.matern_kernel import MaternKernel\n",
    "from gpytorch.kernels import ScaleKernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "510ee306",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common transform to convert PIL image to tensor\n",
    "transform = transforms.ToTensor()\n",
    "\n",
    "# Fashion MNIST\n",
    "full_fashion = ConcatDataset([\n",
    "    datasets.FashionMNIST(root='./data', train=True, download=True, transform=transform),\n",
    "    datasets.FashionMNIST(root='./data', train=False, download=True, transform=transform)\n",
    "])\n",
    "\n",
    "# Digit MNIST\n",
    "full_mnist = ConcatDataset([\n",
    "    datasets.MNIST(root='./data', train=True, download=True, transform=transform),\n",
    "    datasets.MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "])\n",
    "\n",
    "def dataset_to_numpy(dataset):\n",
    "    images = []\n",
    "    labels = []\n",
    "    for img, label in dataset:\n",
    "        images.append(img.numpy())  # shape: (1, 28, 28)\n",
    "        labels.append(label)\n",
    "    return np.array(images), np.array(labels)\n",
    "\n",
    "x_mnist, y_mnist = dataset_to_numpy(full_mnist)\n",
    "x_fashion, y_fashion = dataset_to_numpy(full_fashion)\n",
    "\n",
    "x_mnist = x_mnist.reshape((x_mnist.shape[0], -1))\n",
    "x_fashion = x_fashion.reshape((x_fashion.shape[0], -1))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
