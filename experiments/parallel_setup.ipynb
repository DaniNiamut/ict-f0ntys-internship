{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b6cf5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from botorch.test_functions.synthetic import Ackley, AckleyMixed, Labs, Griewank\n",
    "import torch\n",
    "from sklearn.decomposition import PCA\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys\n",
    "sys.path.append('../')\n",
    "from roelfes_emulator import RoelfesEmulator\n",
    "from vae import Autoencoder, WeightedAutoencoder\n",
    "from bayesian_opt import BayesianOptimization\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51733dff",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_random_inputs(bounds, q, discrete_inds=None):\n",
    "    lower, upper = bounds  \n",
    "    generated_samples = lower + (upper - lower) * torch.rand((q, bounds.shape[1]))\n",
    "    if discrete_inds is not None:\n",
    "        generated_samples[:, discrete_inds] = torch.round(generated_samples[:, discrete_inds])\n",
    "    return generated_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "140bd872",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bayes_opt_roelfes_coef(objs, q, q_sampling_method=\"Monte Carlo\"):\n",
    "    lin_y_names= ['y1','y2']\n",
    "    dec_exp_y_names = ['y3','y4','y5','y6']\n",
    "    all_names = lin_y_names + dec_exp_y_names\n",
    "\n",
    "    lin_df = objs.drop(dec_exp_y_names,axis=1)\n",
    "    dec_exp_df = objs.drop(lin_y_names, axis=1)\n",
    "\n",
    "    q1 = q // 2\n",
    "    q2 = q - q1\n",
    "    if q == 1:\n",
    "        q1 = 1\n",
    "\n",
    "    lin_bo_model = BayesianOptimization().fit(lin_df, y=lin_y_names)\n",
    "    c1 = lin_bo_model.candidates(q1, export_df=True, q_sampling_method=q_sampling_method)\n",
    "    dec_exp_bo_model = BayesianOptimization().fit(dec_exp_df, y=dec_exp_y_names, \n",
    "                                                optim_direc=['max','max', 'min','max'])\n",
    "    c2 = dec_exp_bo_model.candidates(q2, export_df=True,q_sampling_method=q_sampling_method)\n",
    "    cand = pd.concat((c1, c2)).fillna(0)\n",
    "    pred = cand[all_names].to_numpy()\n",
    "    cand = cand.drop(all_names, axis=1).to_numpy()\n",
    "    if q == 1:\n",
    "        choice = np.random.randint(0,2)\n",
    "        return cand[choice,:], pred[choice,:]\n",
    "        \n",
    "    return cand, pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f0cd6234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example definitions (ensure you run these first)\n",
    "starting_samples_n = 96\n",
    "cv_amount = 2\n",
    "q_list = [1, 96]\n",
    "sampling_strategies = [\"Monte Carlo\", \"Believer\"]\n",
    "test_component_choice_list = [2, 16, 32]\n",
    "dim_red_list = [PCA, Autoencoder, WeightedAutoencoder, None]  # Replace with actual class references\n",
    "\n",
    "# Define your function list and objective directions\n",
    "function_list = [\n",
    "    (\"Ackley\", Ackley(dim=50)),\n",
    "    (\"AckleyMixed\", AckleyMixed(dim=53)),\n",
    "    (\"Labs\", Labs(dim=50)),\n",
    "    (\"Griewank\", Griewank(dim=50)),\n",
    "    (\"RoelfesCoef\", RoelfesEmulator(dim=50, objective=\"coef\", use_torch=True)),\n",
    "    (\"RoelfesMaxYield\", RoelfesEmulator(dim=50, objective=\"max yield\", use_torch=True)),\n",
    "    (\"RoelfesNormGrad\", RoelfesEmulator(dim=50, objective=\"normalized yield gradient\", use_torch=True)),\n",
    "]\n",
    "\n",
    "optim_direc_map = {\n",
    "    \"Ackley\": [\"min\"],\n",
    "    \"AckleyMixed\": [\"min\"],\n",
    "    \"Labs\": [\"min\"],\n",
    "    \"Griewank\": [\"min\"],\n",
    "    \"RoelfesCoef\": [\"max\", \"max\", \"max\", \"max\", \"min\", \"max\"],\n",
    "    \"RoelfesMaxYield\": [\"max\"],\n",
    "    \"RoelfesNormGrad\": [\"max\"],\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf05c656",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   2 tasks      | elapsed:   18.7s\n",
      "[Parallel(n_jobs=-1)]: Done   9 tasks      | elapsed:  1.2min\n",
      "[Parallel(n_jobs=-1)]: Done  16 tasks      | elapsed:  4.8min\n",
      "[Parallel(n_jobs=-1)]: Done  25 tasks      | elapsed: 13.0min\n",
      "[Parallel(n_jobs=-1)]: Done  34 tasks      | elapsed: 14.2min\n",
      "[Parallel(n_jobs=-1)]: Done  45 tasks      | elapsed: 16.2min\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 86\u001b[39m\n\u001b[32m     83\u001b[39m                         tasks.append((function_name, function, cv_iter, dr_method, n_components, q, q_method))\n\u001b[32m     85\u001b[39m \u001b[38;5;66;03m# Run in parallel (adjust n_jobs based on available CPUs)\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m86\u001b[39m results_list = \u001b[43mParallel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     87\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_experiment\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtasks\u001b[49m\n\u001b[32m     88\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:2007\u001b[39m, in \u001b[36mParallel.__call__\u001b[39m\u001b[34m(self, iterable)\u001b[39m\n\u001b[32m   2001\u001b[39m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[32m   2002\u001b[39m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[32m   2003\u001b[39m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[32m   2004\u001b[39m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[32m   2005\u001b[39m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[32m-> \u001b[39m\u001b[32m2007\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.return_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1650\u001b[39m, in \u001b[36mParallel._get_outputs\u001b[39m\u001b[34m(self, iterator, pre_dispatch)\u001b[39m\n\u001b[32m   1647\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m   1649\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backend.retrieval_context():\n\u001b[32m-> \u001b[39m\u001b[32m1650\u001b[39m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m._retrieve()\n\u001b[32m   1652\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[32m   1653\u001b[39m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[32m   1654\u001b[39m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[32m   1655\u001b[39m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[32m   1656\u001b[39m     \u001b[38;5;28mself\u001b[39m._exception = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\danin\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\joblib\\parallel.py:1762\u001b[39m, in \u001b[36mParallel._retrieve\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._jobs) == \u001b[32m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[32m   1760\u001b[39m     (\u001b[38;5;28mself\u001b[39m._jobs[\u001b[32m0\u001b[39m].get_status(\n\u001b[32m   1761\u001b[39m         timeout=\u001b[38;5;28mself\u001b[39m.timeout) == TASK_PENDING)):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43msleep\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m0.01\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m   1763\u001b[39m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[32m   1765\u001b[39m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[32m   1766\u001b[39m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[32m   1767\u001b[39m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from joblib import Parallel, delayed\n",
    "import itertools\n",
    "\n",
    "\n",
    "def run_experiment(function_name, function, cv_iter, dr_method, n_components, q, q_method):\n",
    "    optim_direc = optim_direc_map[function_name]\n",
    "    weights = np.array([1 if d == \"max\" else -1 for d in optim_direc])\n",
    "\n",
    "    # Generate input data\n",
    "    X = generate_random_inputs(function.bounds, starting_samples_n, function.discrete_inds)\n",
    "    y = function(X)\n",
    "    x_np, y_np = X.numpy(), y.numpy()\n",
    "    x_np_backup, y_np_backup = x_np.copy(), y_np.copy()\n",
    "\n",
    "    dr_name = dr_method.__name__ if dr_method else \"None\"\n",
    "    q_key = f\"q{q}_{q_method or 'None'}\"\n",
    "\n",
    "    best_vals = []\n",
    "    mae_pred_vals = []\n",
    "    recon_mae_vals = []\n",
    "\n",
    "    for bo_iter in range(5):\n",
    "        x_np, y_np = x_np_backup.copy(), y_np_backup.copy()\n",
    "\n",
    "        if dr_method:\n",
    "            dr_model = dr_method(n_components=n_components)\n",
    "            if dr_name == \"WeightedAutoencoder\":\n",
    "                x_np_dr = dr_model.fit_transform(x_np, y_np, optim_direc=optim_direc)\n",
    "            else:\n",
    "                x_np_dr = dr_model.fit_transform(x_np)\n",
    "            x_np_recon = dr_model.inverse_transform(x_np_dr)\n",
    "            recon_mae_vals.append(mean_absolute_error(x_np_recon, x_np))\n",
    "        else:\n",
    "            x_np_dr = x_np\n",
    "            recon_mae_vals.append(mean_absolute_error(x_np_dr, x_np))\n",
    "\n",
    "        x_cols = [f\"x{i+1}\" for i in range(x_np_dr.shape[1])]\n",
    "        if len(optim_direc) > 1:\n",
    "            y_cols = [f\"y{i+1}\" for i in range(y_np.shape[1])]\n",
    "        else:\n",
    "            y_cols = ['y1']\n",
    "            y_np = y_np.reshape(len(y_np), 1)\n",
    "\n",
    "        df = pd.DataFrame(np.hstack([x_np_dr, y_np]), columns=x_cols + y_cols)\n",
    "\n",
    "        if isinstance(function, RoelfesEmulator) and function.objective == \"coef\":\n",
    "            cand, pred = bayes_opt_roelfes_coef(df, q, q_method)\n",
    "            pred = pred.reshape(1, len(pred))\n",
    "        else:\n",
    "            model = BayesianOptimization().fit(df, y_cols, optim_direc=optim_direc)\n",
    "            cand, pred = model.candidates(q, q_sampling_method=q_method)\n",
    "\n",
    "        recon_cand = dr_model.inverse_transform(cand) if dr_method else cand\n",
    "        rc_tensor = torch.tensor(recon_cand)\n",
    "        recon_cand = torch.max(torch.min(rc_tensor, function.bounds[1].unsqueeze(0)),\n",
    "                               function.bounds[0].unsqueeze(0))\n",
    "        if function.discrete_inds is not None:\n",
    "            recon_cand[:, function.discrete_inds] = torch.round(recon_cand[:, function.discrete_inds])\n",
    "        new_y = function(recon_cand).numpy().reshape(q, 1)\n",
    "        recon_cand = rc_tensor.numpy()\n",
    "\n",
    "        scalar_y = np.dot(new_y, weights.T) if len(weights) > 1 else new_y.flatten() * weights[0]\n",
    "        best_vals.append(np.max(scalar_y))\n",
    "\n",
    "        pred_np = np.array(pred)\n",
    "        mae_pred_vals.append(mean_absolute_error(pred_np, new_y))\n",
    "\n",
    "        x_np = np.vstack([x_np, recon_cand])\n",
    "        y_np = np.vstack([y_np, new_y])\n",
    "\n",
    "    return (function_name, dr_name, n_components, q_key, best_vals, mae_pred_vals, recon_mae_vals, x_np)\n",
    "\n",
    "\n",
    "# Generate parameter combinations\n",
    "tasks = []\n",
    "for function_name, function in function_list:\n",
    "    for cv_iter in range(cv_amount):\n",
    "        for dr_method in dim_red_list:\n",
    "            for n_components in test_component_choice_list:\n",
    "                for q in q_list:\n",
    "                    sampling_strats = sampling_strategies if q > 1 else [None]\n",
    "                    for q_method in sampling_strats:\n",
    "                        tasks.append((function_name, function, cv_iter, dr_method, n_components, q, q_method))\n",
    "\n",
    "# Run in parallel (adjust n_jobs based on available CPUs)\n",
    "results_list = Parallel(n_jobs=-1, verbose=10)(\n",
    "    delayed(run_experiment)(*args) for args in tasks\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2693b80c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_x = train_x.to_numpy(dtype=np.float64).reshape(-1,np.shape(train_x)[1])\n",
    "# train_y = train_y.to_numpy(dtype=np.float64).reshape(-1,np.shape(train_y)[1])\n",
    "#for bayesian_opt.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f10f672",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "data = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e5b1a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for function_name, dr_name, n_components, q_key, best_vals, mae_vals, recon_mae, final_x in results_list:\n",
    "    r = results.setdefault(function_name, {}).setdefault(dr_name, {}).setdefault(n_components, {}).setdefault(q_key, {\n",
    "        \"x\": [],\n",
    "        \"best_vals_all_folds\": [],\n",
    "        \"mae_vals_all_folds\": [],\n",
    "        \"recon_mae_all_folds\": []\n",
    "    })\n",
    "    d = data.setdefault(function_name, {}).setdefault(dr_name, {}).setdefault(n_components, {}).setdefault(q_key, {})\n",
    "\n",
    "    r[\"x\"].append(final_x)\n",
    "    r[\"best_vals_all_folds\"].append(best_vals)\n",
    "    r[\"mae_vals_all_folds\"].append(mae_vals)\n",
    "    r[\"recon_mae_all_folds\"].append(recon_mae)\n",
    "\n",
    "# Final aggregation same as before\n",
    "for fname in results:\n",
    "    for dr in results[fname]:\n",
    "        for comp in results[fname][dr]:\n",
    "            for q_key in results[fname][dr][comp]:\n",
    "                data[fname][dr][comp][q_key][\"best_vals_avg\"] = np.mean(\n",
    "                    results[fname][dr][comp][q_key][\"best_vals_all_folds\"], axis=0)\n",
    "                data[fname][dr][comp][q_key][\"mae_vals_avg\"] = np.mean(\n",
    "                    results[fname][dr][comp][q_key][\"mae_vals_all_folds\"], axis=0)\n",
    "                data[fname][dr][comp][q_key][\"recon_mae_avg\"] = np.mean(\n",
    "                    results[fname][dr][comp][q_key][\"recon_mae_all_folds\"], axis=0)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
